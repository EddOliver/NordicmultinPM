/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 19.02.2023 02:00:43

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 39248;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[23];
TfLiteEvalTensor tflEvalTensors[23];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[11];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,18915 } };
const TfArray<1, float> quant0_scale = { 1, { 0.0020268440712243319, } };
const TfArray<1, int> quant0_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 291, 65, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 291, 1, 8, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 146, 8, };
const TfArray<1, int> tensor_dimension3 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data4[4] = { 1, 146, 1, 16, };
const TfArray<1, int> tensor_dimension4 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data5[2] = { -1, 1168, };
const TfArray<1, int> tensor_dimension5 = { 1, { 2 } };
const ALIGN(16) int8_t tensor_data6[8*1*3*65] = { 
  /* [0][0][][] */ -93,39,-95,71,86,-76,47,75,79,-72,-21,78,-5,112,-41,-107,-40,-14,-49,-55,-101,52,-15,39,117,114,-125,5,4,-62,-86,9,-72,-26,104,52,-127,-82,-5,-121,115,22,88,-56,-7,86,91,-105,23,-27,109,-15,-59,-51,-25,118,-23,-57,28,-21,-73,-54,78,-57,-14, -115,-108,-27,51,38,-49,100,125,-1,-53,-80,-44,9,-67,-42,24,-55,-12,70,105,38,87,31,-48,-70,-65,-20,-12,65,-14,35,-107,-99,-65,116,86,63,33,-103,27,83,-89,-72,-34,96,-103,-35,55,-6,-54,-28,98,64,95,-53,-57,-88,120,41,52,62,-126,111,-114,-44, -105,27,-22,-69,-97,17,-37,-32,-27,84,14,-106,-104,-97,2,-17,74,7,35,51,14,-21,-55,27,-73,-65,-67,-29,-73,-16,-59,107,-30,-8,78,61,-125,-19,-81,106,-3,5,6,-122,-102,107,48,-48,-9,-101,-12,56,83,26,-12,-23,-88,30,47,87,74,53,102,31,38, 
  /* [1][0][][] */ 17,-6,-56,-71,30,2,12,-119,-21,84,26,-109,111,47,-31,80,-10,21,42,-25,-101,63,-72,-105,94,67,4,11,-77,110,-26,-60,26,-59,-52,-71,10,-20,23,27,-47,33,6,45,-65,87,102,-66,106,102,-9,79,-114,-117,-46,-100,-9,71,-41,-49,40,96,111,58,100, 31,-43,-89,-50,22,-67,109,74,41,-56,101,-98,74,119,127,-121,-4,23,113,60,-114,-19,-112,78,61,-41,-14,114,34,-74,88,-6,-103,-68,-116,-63,-89,-98,32,-8,26,65,-95,68,-36,-103,36,119,79,10,33,83,77,76,-9,-22,-40,14,-11,117,78,-32,-52,5,-77, -114,-75,-58,-55,-27,114,89,119,78,73,-111,-97,-12,-48,117,-25,68,49,13,-54,107,-71,96,-1,5,-69,118,83,6,-18,-42,113,108,-2,81,44,116,-45,50,81,75,91,-13,-92,109,-126,13,93,-53,-100,-33,-65,-121,-116,45,66,52,60,-115,-93,-96,82,-105,125,30, 
  /* [2][0][][] */ -1,-102,-85,114,-126,-100,-120,102,-46,-60,0,119,76,37,-43,-121,41,-3,-29,78,-79,18,-34,68,-47,-43,10,-108,-96,-22,-93,24,94,-90,-34,67,-15,-55,30,-20,-87,-80,-50,60,-58,105,-39,-105,-45,-74,85,-69,80,-16,53,-64,80,-38,-96,46,-57,-55,-81,2,5, 12,-93,94,20,-18,-20,43,24,-36,7,-83,120,70,-37,-4,-111,-118,103,-11,82,-85,110,54,-54,-122,30,-46,54,87,11,-62,-81,28,-50,-43,103,-51,-44,4,-100,-5,102,37,-68,-113,-30,41,120,-4,-1,88,24,-96,108,-123,127,-52,67,56,12,117,115,11,15,7, 22,-103,-92,-46,60,80,76,47,60,-59,77,16,16,56,12,39,-123,-121,19,98,45,-71,12,-35,78,-111,73,125,-41,-35,58,-93,94,-108,9,-60,103,-96,-35,110,66,-124,-91,-17,-115,92,-52,42,67,-20,-47,-72,-7,55,4,-43,39,113,-70,35,-88,-102,-72,36,-13, 
  /* [3][0][][] */ -28,20,-10,24,23,-3,-3,16,-11,8,22,0,16,123,25,1,6,84,34,-16,27,59,90,27,127,21,72,52,31,92,28,72,56,25,66,26,47,83,40,45,14,58,49,3,74,42,68,55,24,70,-1,61,35,6,42,48,42,64,20,33,14,64,69,17,52, 0,-7,-3,6,8,33,-19,-26,19,-1,12,-25,-37,121,-31,25,-23,109,42,23,19,61,74,59,97,32,100,83,49,95,10,91,75,50,89,31,54,37,14,50,15,28,67,10,53,-1,27,33,48,70,43,21,43,49,83,39,38,28,24,71,37,42,73,51,75, -12,19,-10,22,7,-8,23,-12,-2,13,30,18,30,122,-12,36,-31,87,42,-28,-3,18,75,64,92,14,94,65,61,70,10,73,41,47,82,16,82,81,19,38,-11,61,47,12,48,33,29,61,55,50,27,48,46,53,41,27,29,15,33,70,-9,25,65,43,51, 
  /* [4][0][][] */ -3,11,-29,12,29,-32,4,3,-35,3,6,26,-5,-92,-4,-39,5,-118,-60,-19,-6,-40,-64,-74,-101,0,-88,-69,10,-119,-13,-99,-16,-41,-105,-50,-26,-11,-46,-42,-21,-20,-50,-26,-31,-5,-82,-60,-18,-54,-11,-77,-72,-29,-77,-29,-3,-60,-31,-16,-13,-68,-63,4,-42, 29,-31,12,5,1,22,26,-16,-4,32,-6,21,-31,-96,-8,-35,-14,-58,-41,11,-27,-72,-80,-28,-105,9,-98,-32,-29,-99,-40,-97,-49,-16,-58,5,-61,-7,-47,-27,-31,-40,-14,6,-78,-48,-37,-33,-23,-38,11,-26,-24,3,-28,7,-39,-29,22,-34,3,-42,-18,-55,-28, 4,-15,26,-29,7,12,26,5,-4,2,16,23,-12,-97,-8,4,16,-91,-44,-16,-38,-59,-78,-19,-127,-24,-73,-67,-2,-53,22,-80,-69,0,-88,-7,-29,-32,-24,-54,-10,-16,-68,-52,-20,-22,-81,-64,-41,-77,-23,-36,-35,16,-53,-5,-67,-1,17,-86,-1,-40,-21,-17,-49, 
  /* [5][0][][] */ 11,0,3,2,-1,-12,-11,-13,10,-26,-7,1,23,-94,-12,-4,9,-52,-47,12,-6,-16,-34,-34,-99,-18,-40,-50,-27,-54,13,-39,-55,-20,-61,9,-38,-40,-24,-51,-17,-49,-48,11,-42,9,-23,-15,-34,-14,-24,-54,-42,-29,-42,-18,-14,-38,14,-51,-25,-50,-44,-40,-40, 1,12,10,-20,24,5,21,-2,12,12,5,-29,17,-85,1,-8,3,-79,-54,0,-13,-18,-26,-6,-127,-9,-37,-20,-4,-61,21,-36,-44,1,-49,-7,-42,-22,-21,-26,20,-15,-22,5,-14,-13,-38,-49,-31,-10,-35,-42,-26,-13,-15,-14,-25,-36,12,-46,-12,-39,2,13,-19, -12,-6,-16,24,22,-12,15,-6,-26,-21,3,2,25,-105,-11,10,-26,-95,-28,-20,-12,-17,-46,-37,-108,15,-41,-23,-41,-47,2,-51,-51,0,-63,12,-35,-43,-25,-56,5,-55,-28,2,-31,-35,-13,-17,-28,-16,-25,-31,-38,-6,-56,-23,0,-22,-14,-16,-2,-16,-51,-3,-46, 
  /* [6][0][][] */ -96,-76,-126,-106,-27,-16,127,54,-96,112,-49,61,29,-43,48,37,65,-30,-4,-87,-60,12,13,86,-32,-106,-108,-31,109,-86,-127,-105,-28,108,-13,111,13,-107,-94,89,-27,-69,-30,78,-21,35,-54,-123,-14,-22,24,28,-18,7,-111,118,-74,25,-115,125,32,73,107,41,-107, -63,-95,-66,72,-34,32,-53,-77,-106,-8,56,20,95,-22,49,-80,91,50,-3,13,-46,103,41,47,82,29,32,-18,15,-16,12,-93,-80,-12,77,100,0,-23,6,-126,-111,88,-11,111,-51,-19,-48,14,82,99,93,80,-33,77,58,68,89,-100,-119,10,46,-96,-3,-61,-107, 86,74,-88,2,-57,-120,-21,66,-81,-92,-72,-47,34,105,51,9,92,95,118,39,50,-125,-123,24,-33,19,-29,44,-112,-103,-53,-120,-95,-64,47,41,74,10,-33,113,-58,-93,115,-66,72,-115,91,55,-20,-67,-23,100,123,-65,-105,-49,-38,74,-60,-78,30,102,-32,-110,-73, 
  /* [7][0][][] */ -10,-17,-8,12,10,2,-10,9,-10,11,-9,-7,7,123,-3,26,-18,86,76,-29,46,21,89,74,127,40,64,39,63,99,9,59,71,22,68,12,88,51,55,73,21,54,41,44,35,25,64,65,53,51,22,58,30,21,71,1,51,41,32,34,13,38,77,23,87, 16,14,-10,18,22,27,1,3,18,-28,-5,-28,26,107,-22,-2,-28,63,49,21,28,60,88,33,107,2,72,58,61,67,41,71,64,31,68,33,89,57,36,57,38,78,58,8,68,5,44,36,30,62,38,26,30,30,77,32,32,58,32,29,40,47,38,45,76, -13,5,21,24,-9,28,3,-18,-19,0,17,-3,-5,107,-26,19,-5,65,70,-13,21,53,56,49,86,31,60,75,45,61,5,70,65,56,89,36,51,31,22,81,33,30,55,43,43,-1,71,34,19,44,22,56,32,54,48,35,28,25,24,71,19,35,63,51,72, 
};
const TfArray<4, int> tensor_dimension6 = { 4, { 8,1,3,65 } };
const TfArray<8, float> quant6_scale = { 8, { 0.0012987988302484155, 0.0013029143447056413, 0.0012919517466798425, 0.0061847260221838951, 0.0043966616503894329, 0.0059263561852276325, 0.0012808514293283224, 0.00645084073767066, } };
const TfArray<8, int> quant6_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int32_t tensor_data7[8] = { 0, 0, -430, -872, -1655, -1642, 0, -729, };
const TfArray<1, int> tensor_dimension7 = { 1, { 8 } };
const TfArray<8, float> quant7_scale = { 8, { 2.6324626105633797e-06, 2.6408042685943656e-06, 2.6185846309090266e-06, 1.2535475434560794e-05, 8.9113473222823814e-06, 1.2011800208711065e-05, 2.5960862330975942e-06, 1.3074848538963124e-05, } };
const TfArray<8, int> quant7_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int8_t tensor_data8[16*1*3*8] = { 
  /* [0][0][][] */ -39,-19,-31,114,-18,-68,52,93, 54,-9,-53,36,-16,-71,24,88, 37,-38,48,98,12,30,44,127, 
  /* [1][0][][] */ -35,48,-44,-2,0,-32,36,127, -45,-27,-22,49,-33,2,-8,97, 32,47,16,90,30,-28,-36,118, 
  /* [2][0][][] */ -41,34,-39,-49,16,60,-38,-127, 42,-3,-12,21,23,-10,-38,-51, -14,-41,-22,-62,19,31,22,-75, 
  /* [3][0][][] */ -28,13,4,36,-15,20,-15,127, -13,-9,9,73,23,20,33,81, 1,-39,22,36,-17,13,32,65, 
  /* [4][0][][] */ 7,12,34,38,18,-38,-14,111, -41,-7,8,24,-18,-41,15,127, 40,-37,37,80,-20,24,-27,126, 
  /* [5][0][][] */ 27,-22,-42,49,23,24,7,127, -28,-36,-38,49,17,21,-31,59, -13,2,19,26,22,-10,-32,116, 
  /* [6][0][][] */ 40,12,23,15,19,39,-29,-38, 18,0,20,-60,7,67,-10,-127, -26,39,-2,-40,43,-15,-6,-92, 
  /* [7][0][][] */ -24,-27,34,-34,-18,51,34,-69, 20,-38,-25,-15,45,37,29,-127, -41,-39,-27,-23,26,22,-21,-52, 
  /* [8][0][][] */ -30,-24,37,25,-17,-23,2,127, -4,-14,-35,83,25,-2,26,114, 2,-34,24,-8,-8,-40,40,104, 
  /* [9][0][][] */ -18,-52,16,-38,65,72,-67,-104, -3,64,64,-73,35,49,61,-127, -53,-2,53,-23,27,11,31,-82, 
  /* [10][0][][] */ -2,7,37,-27,12,-28,-28,-61, 58,11,8,-2,73,46,56,-127, 3,-1,-6,-70,-13,6,55,-105, 
  /* [11][0][][] */ 6,-24,-6,63,-11,-45,27,85, -14,33,28,17,-21,-18,6,127, 19,11,-40,71,31,-46,34,96, 
  /* [12][0][][] */ 35,4,-50,-35,32,58,21,-127, -14,-4,50,-28,41,-25,32,-66, 1,19,-27,-49,-1,49,3,-53, 
  /* [13][0][][] */ -9,11,-35,7,-30,-16,-10,-127, -39,-20,14,-36,45,22,-44,-121, -18,-48,-32,0,7,42,35,-112, 
  /* [14][0][][] */ 3,9,31,0,-36,70,-28,-127, 16,24,-45,-13,57,16,-2,-96, -25,42,31,-50,8,44,3,-87, 
  /* [15][0][][] */ 54,26,-14,8,-30,-44,-51,-127, -16,14,-5,-78,58,66,64,-99, 47,-46,28,-76,-18,42,-43,-92, 
};
const TfArray<4, int> tensor_dimension8 = { 4, { 16,1,3,8 } };
const TfArray<16, float> quant8_scale = { 16, { 0.004562202375382185, 0.0051602250896394253, 0.0053158355876803398, 0.0066066104918718338, 0.006363977212458849, 0.006273114588111639, 0.0055275070481002331, 0.0062958188354969025, 0.0063037802465260029, 0.0042814044281840324, 0.0047323489561676979, 0.0065633133053779602, 0.0054700984619557858, 0.0054108584299683571, 0.0055078640580177307, 0.0041713854297995567, } };
const TfArray<16, int> quant8_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int32_t tensor_data9[16] = { 1827, 1309, 3369, -361, 1481, -1161, 3069, 505, 805, 4819, 6203, 1221, 3358, 4368, 4591, 2217, };
const TfArray<1, int> tensor_dimension9 = { 1, { 16 } };
const TfArray<16, float> quant9_scale = { 16, { 9.5156865427270532e-06, 1.0763022146420553e-05, 1.1087589882663451e-05, 1.3779844266537111e-05, 1.3273767763166688e-05, 1.3084249076200649e-05, 1.1529086805239785e-05, 1.3131605555827264e-05, 1.3148211110092234e-05, 8.9300083345733583e-06, 9.8705731943482533e-06, 1.3689535990124568e-05, 1.1409345461288467e-05, 1.1285785149084404e-05, 1.1488115887914319e-05, 8.7005337263690308e-06, } };
const TfArray<16, int> quant9_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int8_t tensor_data10[3*1168] = { 
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
  -18, 6, 0, 22, 17, 16, -10, -9, 11, -16, 6, -17, -22, -23, -2, -30, -8, 46, 16, 20, 37, 4, -15, -10, -3, -2, -12, 32, 6, -5, 19, -23, 1, 22, 15, 10, 27, 21, 7, -24, 13, 2, 2, 35, -23, -29, -4, -35, -1, 28, -9, 23, 6, 10, 3, -19, 20, 19, 2, 4, -15, 4, -4, -46, 29, 43, -5, 47, 12, 37, -3, -19, 31, 22, 19, 4, 8, -6, -12, -6, 7, 31, -3, 4, 38, 9, 0, 5, 24, -13, 18, 28, 3, -18, 7, -40, 0, 31, -6, 17, 36, 41, -2, -27, 34, -8, -4, 40, 3, 12, -23, -23, 14, 51, -25, 33, 19, 31, -13, 4, 27, 2, -16, 43, -3, 5, 0, -41, 15, 20, 8, 9, 32, 39, -18, -2, 33, 19, 23, 31, 9, 0, -8, -40, 22, 17, -15, 9, 52, 19, 10, 9, 45, 4, 5, 33, -12, -1, 8, -23, 18, 49, -9, 22, 11, 41, -4, -25, 43, -3, 19, 45, 12, 1, 11, -21, 37, 4, -14, 34, 23, 12, -26, -26, 44, 8, -14, 2, -3, -6, -4, -51, 23, 25, -25, 11, 10, 5, 18, -9, 5, 14, -14, 14, -17, -6, 15, -35, 18, 45, 12, 6, 23, 11, -14, -19, 5, -21, 3, 9, -2, -2, -22, -20, 19, 20, -24, 29, 39, 11, 6, 8, 10, -23, 10, 44, -24, -16, -26, -21, 46, 37, -26, 42, 43, 32, 11, -35, 31, -8, 9, 26, -11, -29, 16, -26, 26, 48, 15, 54, 5, 42, 11, 4, 50, 15, 22, 38, 3, -26, -13, -21, 22, 38, 16, 46, 26, 21, -27, -20, 14, 2, 2, 24, -10, -3, -9, -38, 38, 37, 1, 22, 56, 1, -26, -27, 17, -19, -11, 44, -19, 0, -16, -12, 12, 40, 11, 59, 58, 34, 12, -18, 46, 11, 20, 10, -22, -21, -26, -17, 49, 58, -12, 15, 29, 4, -15, -24, 38, -10, -10, 9, -23, -12, -24, -36, 12, 27, 3, 17, 35, 24, -2, -18, 42, 17, -16, 35, -3, -30, 13, -27, 14, 39, 2, 60, 51, 47, 8, -36, 26, -22, 1, 59, -27, -34, -23, -41, 22, 51, 10, 28, 39, 6, -17, -16, 28, 2, 15, 54, 11, -24, 9, -42, 37, 44, 11, 44, 19, 12, -22, -33, 7, -6, 15, 29, -4, 8, 3, -15, 42, 26, 14, 38, 2, 12, 15, -32, 0, -20, -11, 9, 13, 5, -19, -47, 7, 50, -1, 16, 10, 11, 10, -31, 39, -22, -16, 6, 1, 3, -5, -32, 20, 42, -2, 57, 9, 20, -25, -23, 19, -16, 11, 32, -2, -27, -8, -23, 28, 10, -22, 21, 10, 22, -7, -7, 30, -22, 2, 15, -1, -5, -29, -16, 33, 51, 2, 21, 14, 11, -19, -7, 54, 10, 2, 35, 10, 5, -27, -26, 26, 51, -28, 17, 24, 12, 12, -16, 40, -19, -10, 47, 13, 0, -9, -39, 12, 38, -1, 43, 35, 38, 9, -13, 34, 16, 9, 30, -20, -5, -18, -22, 32, 48, 13, 55, 57, 21, 6, -24, 52, 21, -6, 32, 3, 1, -26, -29, 50, 19, -21, 12, 35, 39, -22, -11, 30, -18, -15, 31, 4, 8, -26, -19, 49, 21, 7, 26, 47, 12, 8, -34, 45, 15, -1, 38, -20, -22, -2, -30, 10, 16, -28, 48, 38, 11, -16, -32, 17, 18, 14, 34, -27, -23, 7, -6, 8, 23, 0, 46, 5, 0, 1, -30, 31, -19, 2, 10, -23, -18, 8, -22, 18, 6, -10, 16, 36, 18, -3, -8, 10, -5, 17, 16, -7, -29, -10, -18, 33, 18, 0, 39, 8, 0, 8, -32, 7, -19, 23, 20, -28, -29, 2, -48, 1, 43, 11, 35, 31, 36, 10, -8, 38, 16, 10, 17, -12, 1, -20, -38, 31, 22, 7, 8, 36, 22, 1, 3, 26, -22, 3, 19, 5, -27, 9, -31, 40, 9, -11, 17, 27, 11, 7, -1, 49, -7, 21, 22, 1, 3, -27, -47, 22, 37, -29, 20, 28, 31, 14, -37, 23, 15, -2, 12, 15, 0, 10, -13, 22, 47, -28, 14, 30, 24, -9, -7, 48, -15, 22, 38, -16, -34, 12, -23, 45, 30, 12, 27, 11, 37, -18, -36, 51, 19, 20, 4, -18, -3, 9, -51, 19, 14, -18, 8, 36, 32, 12, -25, 9, 17, -18, 3, -26, -15, 15, -14, 8, 39, -30, 54, 23, 5, -4, -19, 29, 5, 14, 43, -23, -23, -28, -52, 34, 21, -10, 34, 38, 9, 12, -29, 32, -12, 12, 2, -17, 0, 5, -16, 1, 11, -25, 26, 20, 27, -16, 3, -4, -8, 13, 30, -21, -4, 18, -45, 8, 31, -15, -3, -1, 1, 15, -31, -7, 11, 5, 8, -8, -25, 19, -47, 18, 10, -18, -2, 11, 18, -23, -6, 29, 14, -1, -9, 9, -10, -25, -15, 5, 27, 13, 14, 28, 5, -5, -27, -2, 13, 13, -6, 4, -23, -2, -36, 20, 2, -24, 14, 21, 28, -24, -1, 22, 18, 25, 21, -5, 2, -19, -10, 12, 5, 7, 37, 0, 28, -6, -6, 19, -18, -10, 28, -8, -2, -14, -40, 35, 21, 7, 6, 9, 15, 7, -18, 2, -17, -2, 18, 9, -17, -10, -42, 3, 17, 12, 30, 15, 9, -15, -14, 26, 19, 5, 42, -20, -27, 14, -11, 35, 26, -18, 30, 33, 7, -24, 3, 22, -3, 1, 34, -2, 1, 8, -43, 30, 35, 4, 23, 33, 28, -27, -17, 35, 13, 6, 32, -2, -28, -4, -14, 55, 50, 5, 17, 51, 43, -9, -16, 40, 14, 20, 14, -6, -21, -12, -11, 21, 34, 13, 16, 6, 38, 14, -12, 34, 21, -2, 18, 10, -21, 14, -51, 15, 17, 10, 15, 14, -6, 8, -7, 18, -16, -6, 19, -21, 2, 11, -31, 5, 12, 19, -10, 12, -1, 9, -4, -4, -6, 2, -7, 19, -11, 11, -11, -16, -3, -6, 31, -2, 28, -24, 1, -3, -12, 25, 1, -2, -18, -9, -13, -5, 2, -24, -5, -16, 16, 7, -26, -4, 6, -15, 24, -11, -18, -15, -49, -6, 6, 15, 22, -4, 31, -22, -6, -2, 2, -5, 13, -5, -19, -3, -46, 28, 28, 14, 29, 17, 17, -18, 0, 4, 11, 11, -7, 3, -12, -7, -22, 33, 9, -11, 26, 35, 5, -5, -26, 46, 13, -15, 0, 2, 5, 1, -28, 16, 22, -16, 37, 8, 24, 13, -18, 35, -9, -16, 22, -7, -22, 3, -42, 23, 24, -20, 23, 4, 39, 5, -26, 5, -4, -6, 45, -23, -15, 13, -51, 4, 32, 14, 47, 16, 20, -18, -36, 13, -16, 2, 29, 4, -8, 1, -41, 9, 41, 14, 25, 7, 32, -20, 7, 14, -20, -17, 12, -12, 11, -21, -32, 27, -7, 6, -1, -15, 5, -15, -29, 3, 14, -9, -9, -3, -17, -17, -23, -8, 18, 21, 25, 0, -10, -16, -2, -2, 19, -2, -45, -14, 21, 7, 10, 
};
const TfArray<2, int> tensor_dimension10 = { 2, { 3,1168 } };
const TfArray<1, float> quant10_scale = { 1, { 0.0030264840461313725, } };
const TfArray<1, int> quant10_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(8) int32_t tensor_data11[3] = { -372, -1739, 1639, };
const TfArray<1, int> tensor_dimension11 = { 1, { 3 } };
const TfArray<1, float> quant11_scale = { 1, { 1.5755218555568717e-05, } };
const TfArray<1, int> quant11_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,1,291,65 } };
const TfArray<1, float> quant12_scale = { 1, { 0.0020268440712243319, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,1,291,8 } };
const TfArray<1, float> quant13_scale = { 1, { 0.0020857660565525293, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1,291,1,8 } };
const TfArray<1, float> quant14_scale = { 1, { 0.0020857660565525293, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1,146,1,8 } };
const TfArray<1, float> quant15_scale = { 1, { 0.0020857660565525293, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,1,146,8 } };
const TfArray<1, float> quant16_scale = { 1, { 0.0020857660565525293, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,1,146,16 } };
const TfArray<1, float> quant17_scale = { 1, { 0.0052057825960218906, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,146,1,16 } };
const TfArray<1, float> quant18_scale = { 1, { 0.0052057825960218906, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,73,1,16 } };
const TfArray<1, float> quant19_scale = { 1, { 0.0052057825960218906, } };
const TfArray<1, int> quant19_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<2, int> tensor_dimension20 = { 2, { 1,1168 } };
const TfArray<1, float> quant20_scale = { 1, { 0.0052057825960218906, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<2, int> tensor_dimension21 = { 2, { 1,3 } };
const TfArray<1, float> quant21_scale = { 1, { 0.35583111643791199, } };
const TfArray<1, int> quant21_zero = { 1, { 39 } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfArray<2, int> tensor_dimension22 = { 2, { 1,3 } };
const TfArray<1, float> quant22_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant22_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&quant22_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 12 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 12,6,7 } };
const TfArray<1, int> outputs1 = { 1, { 13 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 13,2 } };
const TfArray<1, int> outputs2 = { 1, { 14 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 14 } };
const TfArray<1, int> outputs3 = { 1, { 15 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 15,3 } };
const TfArray<1, int> outputs4 = { 1, { 16 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 16,8,9 } };
const TfArray<1, int> outputs5 = { 1, { 17 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 17,4 } };
const TfArray<1, int> outputs6 = { 1, { 18 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 18 } };
const TfArray<1, int> outputs7 = { 1, { 19 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 19,5 } };
const TfArray<1, int> outputs8 = { 1, { 20 } };
const TfLiteFullyConnectedParams opdata9 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs9 = { 3, { 20,10,11 } };
const TfArray<1, int> outputs9 = { 1, { 21 } };
const TfLiteSoftmaxParams opdata10 = { 1 };
const TfArray<1, int> inputs10 = { 1, { 21 } };
const TfArray<1, int> outputs10 = { 1, { 22 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 18928, (TfLiteIntArray*)&tensor_dimension0, 18915, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 1560, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 384, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data10, (TfLiteIntArray*)&tensor_dimension10, 3504, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data11, (TfLiteIntArray*)&tensor_dimension11, 12, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 18915, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 18928, (TfLiteIntArray*)&tensor_dimension13, 2328, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 2328, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 2336, (TfLiteIntArray*)&tensor_dimension15, 1168, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 1168, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 2336, (TfLiteIntArray*)&tensor_dimension17, 2336, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension18, 2336, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant18))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 2336, (TfLiteIntArray*)&tensor_dimension19, 1168, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant19))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension20, 1168, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant20))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 1168, (TfLiteIntArray*)&tensor_dimension21, 3, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant21))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension22, 3, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant22))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs8, (TfLiteIntArray*)&outputs8, const_cast<void*>(static_cast<const void*>(&opdata8)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs9, (TfLiteIntArray*)&outputs9, const_cast<void*>(static_cast<const void*>(&opdata9)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs10, (TfLiteIntArray*)&outputs10, const_cast<void*>(static_cast<const void*>(&opdata10)), OP_SOFTMAX, },
};
static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return &tflTensors[tensor_idx];
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return &tflEvalTensors[tensor_idx];
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 23;
  for (size_t i = 0; i < 23; ++i) {
    tflTensors[i].type = tensorData[i].type;
    tflEvalTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    tflEvalTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
     tflEvalTensors[i].data.data =  start;
    }
    else {
       tflTensors[i].data.data = tensorData[i].data;
       tflEvalTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
    tflEvalTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    }
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 11; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 11; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  22, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for (size_t i = 0; i < 11; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
